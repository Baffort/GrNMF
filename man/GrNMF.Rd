% Generated by roxygen2 (4.0.2): do not edit by hand
\name{grnmf}
\alias{grnmf}
\title{A Network Constrained Version of Non-negative Matrix Factorization.}
\usage{
grnmf(Xr, Wr, k = 5L, lambda_multiple = 1L, n_iter = 10000L,
  converge = 1e-06, dynamic_lambda = TRUE)
}
\arguments{
\item{Xr}{an p by n non-negative numeric matrix with each column being a sample, and each row corresponding to a feature.}

\item{Wr}{a symmetric numeric matrix (p by p) with 1 iff x_i,j and x_i',j' are nearest neighbors by some
graph distance metric, and 0 otherwise. You decide/compute this in advance, 11 is a good neighbor threshold from Hofree et al 2013.}

\item{k}{the number of inner dimensions (reduced features, or 'rank') to use for the NMF algorithm.}

\item{lambda_multiple}{the scalar weight applied to the graphical constaint term, or the multiple applied to the update term}

\item{n_iter}{the number of optimization loop iterations.}

\item{converge}{threshold for convergence test for early termination. Negative values deactivate this feature.}

\item{dynamic_lambda}{Should we use the dynamic lambda updating scheme of Hofree et al? This makes
lambda_multiple the multiple applied to the dynamic updating term rather than the lambda that is applied to
directly to the network influence term on the GrNMF objective function.}
}
\value{
a list of \code{U},
  (sometimes called \code{W}) and \code{V}
  (sometimes called \code{H}) for the NNLS fit.
  \code{Max.iter} which stores the maximum iteration before NMF converged
  Additionally the standard NMF objective
  function fit is returned as \code{ObjectiveFitNMF}.
  The full GrNMF objective function score is retured as
  \code{ObjectiveFitGrNMF}
}
\description{
\code{grnmf} is an R/C++ implementation of the algorithm described in "Non-negative Matrix Factorization on Manifold", and modified slightly as
  described in Hofree et al 2013 to put the constraint on features rather than samples.
}
\examples{
# The following is adapted from the NMF package vignette
# and uses their functions to set up demo data, and as an NMF implementation
# comparison (see http://cran.r-project.org/package=NMF)

# First, generate a synthetic dataset with known classes: 100 features, 23 samples (10+5+8)

library(NMF)
set.seed(1234)
p <- 100; counts <- c(10, 5, 8);
n <- sum(counts)
x <- syntheticNMF(p, counts)
dim(x)
# build the true cluster membership
groups <- unlist(mapply(rep, seq(counts), counts))
# run on a data.frame
set.seed(10)
system.time(res <- nmf(data.frame(x), 3, nmfAlgorithm("lee"), "random"))


# Now do the same for GrNMF, and let's compare how close they are
d<-as.matrix(dist(x))
nn<-5 # 5 nearest neighbors for adjacency graph construction
adj <- apply(d, 1, function(drow){
  cut <- sort(drow,partial=nn+1)[nn+1] #this is the nn+1 smallest
  ifelse(drow<cut,1,0)
})
adj <- (adj | t(adj)) + 0 #make it symmetric,
  # (the + 0 turns it back to numeric 0/1)
sum(adj!=t(adj)) == 0

set.seed(10)

# turn off the graphical part for this comparison
# by setting lambda to 0
system.time(res2<-grnmf(x,adj,lambda_multiple=0,k=3))

##
# now we can compare the two fits to the NMF
# objective function

# first from the NMF package
norm(as.matrix(data.frame(x)- (res@fit@W \%*\% res@fit@H)),'F')
# and next get the NMF objective function fit from grnmf
res2$ObjectiveFitNMF

#it should be the same as the GrNMF fit because lambda=0
res2$ObjectiveFitNMF == res2$ObjectiveFitGrNMF

# Now test out but use our demo graph
set.seed(10)
system.time(res3<-grnmf(x, adj, k=3))
res3$ObjectiveFitNMF
res3$ObjectiveFitGrNMF


##
# Now do some simple clustering with kmeans

# function to check if our clusters (which are assigned an arbitrary label)
# are the same
check_fit <- function(cluster){
  c1 = cluster[1:counts[1]]
  c2 = cluster[(counts[1]+1):(counts[1]+counts[2])]
  c3 = cluster[(counts[1]+counts[2]+1):sum(counts)]
  c1m = median(c1)
  c2m = median(c2)
  c3m = median(c3)
  if(length(unique(c(c1m,c2m,c3m))) != 3){
    cat("Warning, the following error estimate will be",
    "incorrect, there are a large number of prediction errors!\\n")
  }
  correct <- ifelse(c(c1-c1m,
    c2-c2m,
    c3-c3m
  ) == 0, 1, 0)
  correct
}

# on raw X matrix
fit_ori <- kmeans(t(x),3)
sum(check_fit(fit_ori$cluster))/n

# on standard NMF matrix
fit_nmf <- kmeans(t(res@fit@H),3)
sum(check_fit(fit_nmf$cluster))/n

# our GrNMF should be equivalent when lambda=0
fit_nmf2 <- kmeans(res2$V,3)
sum(check_fit(fit_nmf2$cluster))/n

# our GrNMF based clusters
fit_grnmf <- kmeans(res3$V,3)
sum(check_fit(fit_grnmf$cluster))/n
}
\references{
Cai, D., He, X., Wu, X., & Han, J. (2008). Non-negative Matrix Factorization on Manifold. 2008 Eighth IEEE International Conference on Data Mining (ICDM), 63–72. doi:10.1109/ICDM.2008.57

Xu, W., Liu, X., & Gong, Y. (2003). Document clustering based on non-negative matrix factorization. the 26th annual international ACM SIGIR conference (pp. 267–273). New York, New York, USA: ACM. doi:10.1145/860435.860485

Hofree, M., Shen, J. P., Carter, H., Gross, A., & Ideker, T. (2013). Network-based stratification of tumor mutations. Nature Methods, 10(11), 1108–1115. doi:10.1038/nmeth.2651
}

